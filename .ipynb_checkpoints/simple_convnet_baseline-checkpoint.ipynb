{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ConvNet Baseline\n",
    "This simple model is used as baseline to be compared with other models to be constructed. It acts as a simple benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "# Used to split test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Keras is a high level wrapper on top of tensorflow (machine learning library)\n",
    "# The Sequential container is a linear stack of layers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "# Popular optimization strategy that uses gradient descent \n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "# To save our model periodically as checkpoints for loading later\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Types of layers do we want our model to have\n",
    "from tensorflow.python.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Cropping2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seed():\n",
    "    '''\n",
    "    Set all the random seed generator to a fixed value to reproduce the same results at every training\n",
    "    '''\n",
    "    # Set a seed value\n",
    "    seed_value= 12321 \n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.compat.v1.set_random_seed(seed_value)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"training_data/baseline_batch/\"\n",
    "data = \"path\"\n",
    "x_training = np.load(DATA_PATH + \"input.npy\")\n",
    "y_training = np.load(DATA_PATH + \"output.npy\")\n",
    "\n",
    "INPUT_SHAPE = np.shape(x_training)[1:]\n",
    "print(INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(data = \"path\"):\n",
    "    \"\"\"\n",
    "    NVIDIA model used, referenced as a starting point\n",
    "    Image normalization to avoid saturation and make gradients work better.\n",
    "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Drop out (0.5)\n",
    "    Fully connected: neurons: 100, activation: ELU\n",
    "    Fully connected: neurons: 50, activation: ELU\n",
    "    Fully connected: neurons: 10, activation: ELU\n",
    "    Fully connected: neurons: 1 (output)\n",
    "    # the convolution layers are meant to handle feature engineering\n",
    "    the fully connected layer for predicting the steering angle.\n",
    "    dropout avoids overfitting\n",
    "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. \n",
    "    \"\"\"\n",
    "    reset_random_seed()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \"\"\"\n",
    "    # Image normalization to avoid saturation and make gradients work better.\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    \"\"\"\n",
    "    model.add(Lambda(lambda x: x /255.0 - 0.5, input_shape=INPUT_SHAPE ))\n",
    "    # Convolutions\n",
    "    model.add(Conv2D(24, 5, strides=(2, 2), padding = \"same\", activation='elu'))\n",
    "    model.add(Conv2D(36, 5, strides=(2, 2), padding = \"same\", activation='elu'))\n",
    "    model.add(Conv2D(48, 5, strides=(2, 2), padding = \"same\", activation='elu'))\n",
    "    model.add(Conv2D(64, 3, strides=(1, 1), padding = \"same\", activation='elu'))\n",
    "    model.add(Conv2D(64, 3, strides=(1, 1), padding = \"same\", activation='elu'))\n",
    "    # Drop out (0.5)\n",
    "    model.add(Dropout(0.5, seed=seed_value))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if data == \"path\":\n",
    "        model.add(Dense(512, activation='elu'))\n",
    "        model.add(Dropout(0.5, seed=seed_value))\n",
    "        model.add(Dense(256, activation='elu'))\n",
    "        model.add(Dropout(0.2, seed=seed_value))\n",
    "        model.add(Dense(100, activation='elu'))\n",
    "    else:\n",
    "        # FCNs\n",
    "        model.add(Dense(100, activation='elu'))\n",
    "        model.add(Dense(50, activation='elu'))\n",
    "        model.add(Dense(10, activation='elu'))\n",
    "        model.add(Dense(1, activation='elu'))\n",
    "        \n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 6, 128, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 3, 64, 24)         153624    \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 2, 32, 36)         21636     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 16, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 16, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 16, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 964,976\n",
      "Trainable params: 964,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 8\n",
    "\n",
    "model = construct_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a dumb baseline, we should make sure the following:\n",
    "    1. Random seed is fixed so that the data is training to reproduce the same thing very single time. This removes a factor of variation and will help keep you sane. For more information, read [here](https://medium.com/@ODSC/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62/62 [==============================] - 5s 87ms/step - loss: 4.0696 - val_loss: 1.2993\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 3.5418 - val_loss: 1.5991\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 3.2029 - val_loss: 0.9790\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 4.9633 - val_loss: 4.3623\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 5.1538 - val_loss: 3.6091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205b719f400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# Using adam optimizer and also mean squared error as the loss function\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "'''\n",
    "checkpoint = ModelCheckpoint(\"simple_v1.h5\", monitor='val_loss', verbose=1,\n",
    "                                  save_best_only=True, mode='min')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_mean_squared_error', min_delta=0.0001, patience=10,\n",
    "                                verbose=1, mode='min')\n",
    "\n",
    "\n",
    "model.fit(x_training, y_training, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                      callbacks=[checkpoint, early_stop], validation_split=0.20, shuffle=False)\n",
    "\n",
    "model.save('simple_v1.h5')\n",
    "'''\n",
    "\n",
    "model.fit(x_training, y_training, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.5904 - val_loss: 0.6221\n"
     ]
    }
   ],
   "source": [
    "print(\"loss: 3.5904 - val_loss: 0.6221\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
