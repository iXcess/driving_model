{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.0\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\miniconda3\\envs\\carnd\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['datetime', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import math\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from tensorflow_model.efficientnet import EfficientNet\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.3.0 or above.\"\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to other families by referencing: \n",
    "# ~\\miniconda3\\envs\\carnd\\Lib\\site-packages\\tensorflow\\python\\keras\\applications\\efficientnet.py\n",
    "\n",
    "def EfficientNetB2(include_top=True,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   classifier_activation='softmax',\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.1,\n",
    "        1.2,\n",
    "        260,\n",
    "        0.3,\n",
    "        model_name='efficientnetb2',\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_imgs (InputLayer)      [(None, 6, 128, 256)]     0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 128, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb2 (Functional)  (None, 4, 8, 1408)        7769439   \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 4, 8, 32)          405536    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "elu (ELU)                    (None, 4, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "vision_features (Flatten)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense1_relu (ReLU)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense2_relu (ReLU)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 8,856,931\n",
      "Trainable params: 8,789,286\n",
      "Non-trainable params: 67,645\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "img_input_data = keras.layers.Input(shape=(6, 128, 256), name=\"input_imgs\")\n",
    "permute1 = keras.layers.Permute((2,3,1))(img_input_data)\n",
    "efficientnet = EfficientNetB2(include_top=False, weights = None, input_shape=(128,256,6))(permute1)\n",
    "conv2d1 = tf.keras.layers.Conv2D(32, 3, padding='same')(efficientnet)\n",
    "normalization = keras.layers.BatchNormalization()(conv2d1)\n",
    "elu1 = tf.keras.layers.ELU(alpha=1.0)(normalization)\n",
    "flatten1 = tf.keras.layers.Flatten(name=\"vision_features\")(elu1)\n",
    "\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(512)(flatten1)\n",
    "dense1_relu = tf.keras.layers.ReLU(name=\"dense1_relu\")(dense1)\n",
    "#droupout1 = tf.keras.layers.Dropout(0.2)(dense1_relu)\n",
    "dense2 = tf.keras.layers.Dense(256)(dense1_relu)\n",
    "dense2_relu = tf.keras.layers.ReLU(name=\"dense2_relu\")(dense2)\n",
    "#droupout2 = tf.keras.layers.Dropout(0.2)(dense2_relu)\n",
    "path = tf.keras.layers.Dense(100)(dense2_relu)\n",
    "\n",
    "output = path\n",
    "model = keras.models.Model(inputs=[img_input_data], outputs=[output])\n",
    "\n",
    "# Renaming all layers which deals with image\n",
    "\"\"\"\n",
    "for layer in model.layers:\n",
    "    layer._name = \"vision_\" + layer.name\n",
    "\"\"\"\n",
    "    \n",
    "#concat = keras.layers.concatenate([input_data, hidden2])\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"training_data/baseline_batch/\"\n",
    "x_training = np.load(DATA_PATH + \"input.npy\")\n",
    "y_training = np.load(DATA_PATH + \"output.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/69 [..............................] - ETA: 0s - loss: 4.9223 - accuracy: 0.0000e+00WARNING:tensorflow:From C:\\Users\\brand\\miniconda3\\envs\\carnd\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/69 [..............................] - ETA: 29s - loss: 3.9646 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0962s vs `on_train_batch_end` time: 0.7703s). Check your callbacks.\n",
      "69/69 [==============================] - 26s 382ms/step - loss: 2.4962 - accuracy: 0.0891 - val_loss: 0.8077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "69/69 [==============================] - 47s 675ms/step - loss: 2.1896 - accuracy: 0.1636 - val_loss: 0.4542 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "69/69 [==============================] - 122s 2s/step - loss: 1.8107 - accuracy: 0.1364 - val_loss: 108.2143 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "69/69 [==============================] - 106s 2s/step - loss: 1.8613 - accuracy: 0.2400 - val_loss: 0.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "69/69 [==============================] - 43s 618ms/step - loss: 1.4969 - accuracy: 0.2745 - val_loss: 0.2990 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "69/69 [==============================] - 38s 557ms/step - loss: 1.2409 - accuracy: 0.1855 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "69/69 [==============================] - 38s 550ms/step - loss: 0.8359 - accuracy: 0.3818 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "69/69 [==============================] - 41s 596ms/step - loss: 0.6742 - accuracy: 0.3545 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "69/69 [==============================] - 60s 874ms/step - loss: 0.3952 - accuracy: 0.4000 - val_loss: 0.1480 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "69/69 [==============================] - 69s 996ms/step - loss: 0.3567 - accuracy: 0.3727 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.3633 - accuracy: 0.3527 - val_loss: 0.6435 - val_accuracy: 0.9677\n",
      "Epoch 12/500\n",
      "69/69 [==============================] - 107s 2s/step - loss: 0.3256 - accuracy: 0.3127 - val_loss: 0.1798 - val_accuracy: 0.1935\n",
      "Epoch 13/500\n",
      "69/69 [==============================] - 99s 1s/step - loss: 0.2148 - accuracy: 0.3764 - val_loss: 0.0789 - val_accuracy: 0.3548\n",
      "Epoch 14/500\n",
      "69/69 [==============================] - 47s 687ms/step - loss: 0.1268 - accuracy: 0.3691 - val_loss: 0.1246 - val_accuracy: 0.0806\n",
      "Epoch 15/500\n",
      "69/69 [==============================] - 44s 643ms/step - loss: 0.1110 - accuracy: 0.3782 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "69/69 [==============================] - 44s 633ms/step - loss: 0.1469 - accuracy: 0.4218 - val_loss: 0.5435 - val_accuracy: 0.6452\n",
      "Epoch 17/500\n",
      "69/69 [==============================] - 52s 748ms/step - loss: 0.1177 - accuracy: 0.3964 - val_loss: 0.2737 - val_accuracy: 0.1935\n",
      "Epoch 18/500\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.0976 - accuracy: 0.4455 - val_loss: 0.1753 - val_accuracy: 0.4839\n",
      "Epoch 19/500\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.1140 - accuracy: 0.4491 - val_loss: 0.4208 - val_accuracy: 0.2097\n",
      "Epoch 20/500\n",
      "69/69 [==============================] - 61s 877ms/step - loss: 0.1100 - accuracy: 0.4127 - val_loss: 0.2705 - val_accuracy: 0.8387\n",
      "Epoch 21/500\n",
      "69/69 [==============================] - 46s 671ms/step - loss: 0.0704 - accuracy: 0.4818 - val_loss: 0.2116 - val_accuracy: 0.8387\n",
      "Epoch 22/500\n",
      "69/69 [==============================] - 50s 722ms/step - loss: 0.1535 - accuracy: 0.4436 - val_loss: 0.2011 - val_accuracy: 0.9032\n",
      "Epoch 23/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0609 - accuracy: 0.4727 - val_loss: 0.1444 - val_accuracy: 0.5484\n",
      "Epoch 24/500\n",
      "69/69 [==============================] - 67s 977ms/step - loss: 0.0704 - accuracy: 0.5073 - val_loss: 0.3025 - val_accuracy: 0.4516\n",
      "Epoch 25/500\n",
      "69/69 [==============================] - 69s 1s/step - loss: 0.0570 - accuracy: 0.5018 - val_loss: 0.1678 - val_accuracy: 0.2742\n",
      "Epoch 26/500\n",
      "69/69 [==============================] - 67s 973ms/step - loss: 0.0816 - accuracy: 0.4618 - val_loss: 0.4268 - val_accuracy: 0.8387\n",
      "Epoch 27/500\n",
      "69/69 [==============================] - 65s 945ms/step - loss: 0.0855 - accuracy: 0.3964 - val_loss: 0.8565 - val_accuracy: 0.5968\n",
      "Epoch 28/500\n",
      "69/69 [==============================] - 46s 670ms/step - loss: 0.0848 - accuracy: 0.4400 - val_loss: 0.0779 - val_accuracy: 0.3871\n",
      "Epoch 29/500\n",
      "69/69 [==============================] - 47s 674ms/step - loss: 0.0875 - accuracy: 0.4327 - val_loss: 0.5994 - val_accuracy: 0.8226\n",
      "Epoch 30/500\n",
      "69/69 [==============================] - 54s 778ms/step - loss: 0.0750 - accuracy: 0.4655 - val_loss: 0.3313 - val_accuracy: 0.8871\n",
      "Epoch 31/500\n",
      "69/69 [==============================] - 91s 1s/step - loss: 0.0535 - accuracy: 0.5036 - val_loss: 0.2498 - val_accuracy: 0.9677\n",
      "Epoch 32/500\n",
      "69/69 [==============================] - 79s 1s/step - loss: 0.0539 - accuracy: 0.5455 - val_loss: 0.1883 - val_accuracy: 0.2258\n",
      "Epoch 33/500\n",
      "69/69 [==============================] - 55s 793ms/step - loss: 0.0467 - accuracy: 0.5309 - val_loss: 0.1665 - val_accuracy: 0.9839\n",
      "Epoch 34/500\n",
      "69/69 [==============================] - 59s 851ms/step - loss: 0.0518 - accuracy: 0.5145 - val_loss: 0.2136 - val_accuracy: 0.6290\n",
      "Epoch 35/500\n",
      "69/69 [==============================] - 68s 982ms/step - loss: 0.0477 - accuracy: 0.5382 - val_loss: 2.1753 - val_accuracy: 0.9677\n",
      "Epoch 36/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0855 - accuracy: 0.5000 - val_loss: 0.3765 - val_accuracy: 0.4839\n",
      "Epoch 37/500\n",
      "69/69 [==============================] - 67s 971ms/step - loss: 0.1102 - accuracy: 0.4982 - val_loss: 0.7189 - val_accuracy: 0.3548\n",
      "Epoch 38/500\n",
      "69/69 [==============================] - 55s 794ms/step - loss: 0.2401 - accuracy: 0.3964 - val_loss: 0.3458 - val_accuracy: 0.1452\n",
      "Epoch 39/500\n",
      "69/69 [==============================] - 46s 672ms/step - loss: 0.1413 - accuracy: 0.4473 - val_loss: 0.1572 - val_accuracy: 0.0323\n",
      "Epoch 40/500\n",
      "69/69 [==============================] - 48s 690ms/step - loss: 0.1424 - accuracy: 0.4600 - val_loss: 0.1479 - val_accuracy: 0.2903\n",
      "Epoch 41/500\n",
      "69/69 [==============================] - 54s 789ms/step - loss: 0.1223 - accuracy: 0.4836 - val_loss: 0.1664 - val_accuracy: 0.7903\n",
      "Epoch 42/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.1143 - accuracy: 0.4709 - val_loss: 0.1185 - val_accuracy: 0.8065\n",
      "Epoch 43/500\n",
      "69/69 [==============================] - 67s 977ms/step - loss: 0.1016 - accuracy: 0.5236 - val_loss: 0.1499 - val_accuracy: 0.8226\n",
      "Epoch 44/500\n",
      "69/69 [==============================] - 69s 1000ms/step - loss: 0.0677 - accuracy: 0.5055 - val_loss: 0.0787 - val_accuracy: 0.9194\n",
      "Epoch 45/500\n",
      "69/69 [==============================] - 51s 745ms/step - loss: 0.0832 - accuracy: 0.4764 - val_loss: 0.2569 - val_accuracy: 0.9032\n",
      "Epoch 46/500\n",
      "69/69 [==============================] - 49s 707ms/step - loss: 0.0640 - accuracy: 0.5036 - val_loss: 0.1425 - val_accuracy: 0.9355\n",
      "Epoch 47/500\n",
      "69/69 [==============================] - 46s 664ms/step - loss: 0.0731 - accuracy: 0.4891 - val_loss: 0.0726 - val_accuracy: 0.8871\n",
      "Epoch 48/500\n",
      "69/69 [==============================] - 63s 919ms/step - loss: 0.0688 - accuracy: 0.5327 - val_loss: 0.1455 - val_accuracy: 0.8226\n",
      "Epoch 49/500\n",
      "69/69 [==============================] - 68s 983ms/step - loss: 0.0663 - accuracy: 0.5491 - val_loss: 0.2004 - val_accuracy: 0.1290\n",
      "Epoch 50/500\n",
      "69/69 [==============================] - 69s 1s/step - loss: 0.0441 - accuracy: 0.5455 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "69/69 [==============================] - 62s 902ms/step - loss: 0.0515 - accuracy: 0.5236 - val_loss: 0.1606 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "69/69 [==============================] - 45s 647ms/step - loss: 0.0392 - accuracy: 0.5727 - val_loss: 0.2315 - val_accuracy: 0.7258\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 47s 677ms/step - loss: 0.0314 - accuracy: 0.6073 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "69/69 [==============================] - 45s 648ms/step - loss: 0.0414 - accuracy: 0.5800 - val_loss: 0.1408 - val_accuracy: 0.9194\n",
      "Epoch 55/500\n",
      "69/69 [==============================] - 45s 657ms/step - loss: 0.0386 - accuracy: 0.5800 - val_loss: 0.1665 - val_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "69/69 [==============================] - 68s 987ms/step - loss: 0.0367 - accuracy: 0.5782 - val_loss: 0.2261 - val_accuracy: 0.8065\n",
      "Epoch 57/500\n",
      "69/69 [==============================] - 94s 1s/step - loss: 0.0587 - accuracy: 0.5836 - val_loss: 0.2400 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "69/69 [==============================] - 67s 975ms/step - loss: 0.0607 - accuracy: 0.5655 - val_loss: 0.1801 - val_accuracy: 0.8548\n",
      "Epoch 59/500\n",
      "69/69 [==============================] - 57s 829ms/step - loss: 0.1434 - accuracy: 0.4836 - val_loss: 0.1857 - val_accuracy: 0.9677\n",
      "Epoch 60/500\n",
      "69/69 [==============================] - 57s 820ms/step - loss: 0.1213 - accuracy: 0.4527 - val_loss: 0.1803 - val_accuracy: 0.8548\n",
      "Epoch 61/500\n",
      "69/69 [==============================] - 60s 876ms/step - loss: 0.0765 - accuracy: 0.5727 - val_loss: 0.2231 - val_accuracy: 0.3871\n",
      "Epoch 62/500\n",
      "69/69 [==============================] - 93s 1s/step - loss: 0.0945 - accuracy: 0.5345 - val_loss: 0.2399 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "69/69 [==============================] - 66s 960ms/step - loss: 0.1111 - accuracy: 0.4345 - val_loss: 0.0906 - val_accuracy: 0.9677\n",
      "Epoch 64/500\n",
      "69/69 [==============================] - 55s 804ms/step - loss: 0.0892 - accuracy: 0.4673 - val_loss: 0.2594 - val_accuracy: 0.8710\n",
      "Epoch 65/500\n",
      "69/69 [==============================] - 56s 818ms/step - loss: 0.1587 - accuracy: 0.4691 - val_loss: 0.5678 - val_accuracy: 0.8710\n",
      "Epoch 66/500\n",
      "69/69 [==============================] - 57s 820ms/step - loss: 0.0734 - accuracy: 0.5091 - val_loss: 0.2676 - val_accuracy: 0.4516\n",
      "Epoch 67/500\n",
      "69/69 [==============================] - 64s 926ms/step - loss: 0.0425 - accuracy: 0.5818 - val_loss: 0.2706 - val_accuracy: 0.9677\n",
      "Epoch 68/500\n",
      "69/69 [==============================] - 67s 975ms/step - loss: 0.0795 - accuracy: 0.5255 - val_loss: 0.8012 - val_accuracy: 0.1452\n",
      "Epoch 69/500\n",
      "69/69 [==============================] - 69s 1s/step - loss: 0.0402 - accuracy: 0.5873 - val_loss: 0.4332 - val_accuracy: 0.8871\n",
      "Epoch 70/500\n",
      "69/69 [==============================] - 48s 689ms/step - loss: 0.0324 - accuracy: 0.5800 - val_loss: 0.3482 - val_accuracy: 0.5806\n",
      "Epoch 71/500\n",
      "69/69 [==============================] - 47s 675ms/step - loss: 0.0295 - accuracy: 0.5927 - val_loss: 0.3294 - val_accuracy: 0.3871\n",
      "Epoch 72/500\n",
      "69/69 [==============================] - 49s 706ms/step - loss: 0.0242 - accuracy: 0.5909 - val_loss: 0.1400 - val_accuracy: 0.9677\n",
      "Epoch 73/500\n",
      "69/69 [==============================] - 48s 694ms/step - loss: 0.0541 - accuracy: 0.5527 - val_loss: 0.2327 - val_accuracy: 0.9677\n",
      "Epoch 74/500\n",
      "69/69 [==============================] - 90s 1s/step - loss: 0.0366 - accuracy: 0.5418 - val_loss: 0.2226 - val_accuracy: 0.9194\n",
      "Epoch 75/500\n",
      "69/69 [==============================] - 85s 1s/step - loss: 0.0469 - accuracy: 0.5818 - val_loss: 0.1095 - val_accuracy: 0.2581\n",
      "Epoch 76/500\n",
      "69/69 [==============================] - 45s 649ms/step - loss: 0.0342 - accuracy: 0.5745 - val_loss: 0.3822 - val_accuracy: 0.1935\n",
      "Epoch 77/500\n",
      "69/69 [==============================] - 45s 648ms/step - loss: 0.0262 - accuracy: 0.5818 - val_loss: 0.2500 - val_accuracy: 0.8387\n",
      "Epoch 78/500\n",
      "69/69 [==============================] - 45s 648ms/step - loss: 0.0227 - accuracy: 0.5927 - val_loss: 0.2849 - val_accuracy: 0.9839\n",
      "Epoch 79/500\n",
      "69/69 [==============================] - 45s 649ms/step - loss: 0.0188 - accuracy: 0.5945 - val_loss: 0.3227 - val_accuracy: 0.9516\n",
      "Epoch 80/500\n",
      "69/69 [==============================] - 81s 1s/step - loss: 0.0193 - accuracy: 0.5818 - val_loss: 0.1839 - val_accuracy: 0.7742\n",
      "Epoch 81/500\n",
      "69/69 [==============================] - 93s 1s/step - loss: 0.0155 - accuracy: 0.5836 - val_loss: 0.2338 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "69/69 [==============================] - 50s 723ms/step - loss: 0.0132 - accuracy: 0.5745 - val_loss: 0.2136 - val_accuracy: 0.9194\n",
      "Epoch 83/500\n",
      "69/69 [==============================] - 46s 674ms/step - loss: 0.0143 - accuracy: 0.6255 - val_loss: 0.2241 - val_accuracy: 0.8065\n",
      "Epoch 84/500\n",
      "69/69 [==============================] - 49s 706ms/step - loss: 0.0116 - accuracy: 0.6145 - val_loss: 0.3192 - val_accuracy: 0.9032\n",
      "Epoch 85/500\n",
      "69/69 [==============================] - 47s 676ms/step - loss: 0.0133 - accuracy: 0.5873 - val_loss: 0.2584 - val_accuracy: 0.7258\n",
      "Epoch 86/500\n",
      "69/69 [==============================] - 67s 964ms/step - loss: 0.0103 - accuracy: 0.5982 - val_loss: 0.1732 - val_accuracy: 0.4194\n",
      "Epoch 87/500\n",
      "69/69 [==============================] - 92s 1s/step - loss: 0.0114 - accuracy: 0.6382 - val_loss: 0.1745 - val_accuracy: 0.6129\n",
      "Epoch 88/500\n",
      "69/69 [==============================] - 56s 806ms/step - loss: 0.0141 - accuracy: 0.6000 - val_loss: 0.2097 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "69/69 [==============================] - 47s 678ms/step - loss: 0.0135 - accuracy: 0.6091 - val_loss: 0.2106 - val_accuracy: 0.7258\n",
      "Epoch 90/500\n",
      "69/69 [==============================] - 49s 703ms/step - loss: 0.0127 - accuracy: 0.5800 - val_loss: 0.2262 - val_accuracy: 0.9355\n",
      "Epoch 91/500\n",
      "69/69 [==============================] - 47s 686ms/step - loss: 0.0112 - accuracy: 0.6145 - val_loss: 0.3110 - val_accuracy: 0.3871\n",
      "Epoch 92/500\n",
      "69/69 [==============================] - 71s 1s/step - loss: 0.0147 - accuracy: 0.5982 - val_loss: 0.5146 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0179 - accuracy: 0.6382 - val_loss: 0.3174 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "69/69 [==============================] - 62s 893ms/step - loss: 0.0176 - accuracy: 0.5745 - val_loss: 0.2151 - val_accuracy: 0.9839\n",
      "Epoch 95/500\n",
      "69/69 [==============================] - 56s 819ms/step - loss: 0.0124 - accuracy: 0.6345 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "69/69 [==============================] - 56s 805ms/step - loss: 0.0164 - accuracy: 0.6200 - val_loss: 0.4762 - val_accuracy: 0.6935\n",
      "Epoch 97/500\n",
      "69/69 [==============================] - 58s 835ms/step - loss: 0.0179 - accuracy: 0.6127 - val_loss: 0.2004 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "69/69 [==============================] - 77s 1s/step - loss: 0.0128 - accuracy: 0.6400 - val_loss: 0.1378 - val_accuracy: 0.9677\n",
      "Epoch 99/500\n",
      "69/69 [==============================] - 87s 1s/step - loss: 0.0172 - accuracy: 0.5764 - val_loss: 0.2240 - val_accuracy: 0.9677\n",
      "Epoch 100/500\n",
      "69/69 [==============================] - 49s 705ms/step - loss: 0.0133 - accuracy: 0.5873 - val_loss: 0.3246 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "69/69 [==============================] - 46s 673ms/step - loss: 0.0163 - accuracy: 0.6200 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "69/69 [==============================] - 44s 643ms/step - loss: 0.0130 - accuracy: 0.6018 - val_loss: 0.2457 - val_accuracy: 0.8226\n",
      "Epoch 103/500\n",
      "69/69 [==============================] - 55s 803ms/step - loss: 0.0142 - accuracy: 0.5745 - val_loss: 0.2097 - val_accuracy: 0.4355\n",
      "Epoch 104/500\n",
      "69/69 [==============================] - 68s 986ms/step - loss: 0.0110 - accuracy: 0.6545 - val_loss: 0.3186 - val_accuracy: 0.9516\n",
      "Epoch 105/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0144 - accuracy: 0.6491 - val_loss: 0.2722 - val_accuracy: 0.9355\n",
      "Epoch 106/500\n",
      "69/69 [==============================] - 65s 939ms/step - loss: 0.0125 - accuracy: 0.6018 - val_loss: 0.2193 - val_accuracy: 0.9677\n",
      "Epoch 107/500\n",
      "69/69 [==============================] - 47s 687ms/step - loss: 0.0093 - accuracy: 0.6327 - val_loss: 0.2016 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "69/69 [==============================] - 47s 687ms/step - loss: 0.0101 - accuracy: 0.6200 - val_loss: 0.2579 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "69/69 [==============================] - 67s 969ms/step - loss: 0.0100 - accuracy: 0.6164 - val_loss: 0.2465 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "69/69 [==============================] - 67s 972ms/step - loss: 0.0097 - accuracy: 0.6455 - val_loss: 0.2003 - val_accuracy: 0.9516\n",
      "Epoch 111/500\n",
      "69/69 [==============================] - 60s 873ms/step - loss: 0.0189 - accuracy: 0.6036 - val_loss: 0.1434 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "69/69 [==============================] - 53s 773ms/step - loss: 0.0145 - accuracy: 0.6291 - val_loss: 0.1838 - val_accuracy: 0.9677\n",
      "Epoch 113/500\n",
      "69/69 [==============================] - 55s 793ms/step - loss: 0.0129 - accuracy: 0.6345 - val_loss: 0.2973 - val_accuracy: 0.9355\n",
      "Epoch 114/500\n",
      "69/69 [==============================] - 57s 825ms/step - loss: 0.0113 - accuracy: 0.6400 - val_loss: 0.2946 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "69/69 [==============================] - 64s 924ms/step - loss: 0.0123 - accuracy: 0.6345 - val_loss: 0.2774 - val_accuracy: 0.9516\n",
      "Epoch 116/500\n",
      "69/69 [==============================] - 91s 1s/step - loss: 0.0174 - accuracy: 0.6545 - val_loss: 0.3339 - val_accuracy: 0.9355\n",
      "Epoch 117/500\n",
      "69/69 [==============================] - 62s 898ms/step - loss: 0.0167 - accuracy: 0.6600 - val_loss: 0.1522 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "69/69 [==============================] - 54s 784ms/step - loss: 0.0361 - accuracy: 0.6145 - val_loss: 0.0885 - val_accuracy: 0.6935\n",
      "Epoch 119/500\n",
      "69/69 [==============================] - 57s 822ms/step - loss: 0.0469 - accuracy: 0.5636 - val_loss: 0.3251 - val_accuracy: 0.3871\n",
      "Epoch 120/500\n",
      "69/69 [==============================] - 54s 789ms/step - loss: 0.1271 - accuracy: 0.4909 - val_loss: 0.9559 - val_accuracy: 0.7419\n",
      "Epoch 121/500\n",
      "69/69 [==============================] - 61s 885ms/step - loss: 0.2103 - accuracy: 0.4873 - val_loss: 0.3837 - val_accuracy: 0.5645\n",
      "Epoch 122/500\n",
      "69/69 [==============================] - 67s 976ms/step - loss: 0.3014 - accuracy: 0.3673 - val_loss: 0.1810 - val_accuracy: 0.6613\n",
      "Epoch 123/500\n",
      "69/69 [==============================] - 69s 1s/step - loss: 0.2221 - accuracy: 0.4582 - val_loss: 1.7975 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "69/69 [==============================] - 50s 723ms/step - loss: 0.0911 - accuracy: 0.5345 - val_loss: 0.2309 - val_accuracy: 0.8226\n",
      "Epoch 125/500\n",
      "69/69 [==============================] - 46s 669ms/step - loss: 0.0786 - accuracy: 0.5764 - val_loss: 0.3661 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "69/69 [==============================] - 46s 671ms/step - loss: 0.0435 - accuracy: 0.6018 - val_loss: 0.3172 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "69/69 [==============================] - 51s 732ms/step - loss: 0.0396 - accuracy: 0.6291 - val_loss: 0.2935 - val_accuracy: 0.9677\n",
      "Epoch 128/500\n",
      "69/69 [==============================] - 68s 988ms/step - loss: 0.0390 - accuracy: 0.6636 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "69/69 [==============================] - 68s 979ms/step - loss: 0.0406 - accuracy: 0.5909 - val_loss: 0.3072 - val_accuracy: 0.3710\n",
      "Epoch 130/500\n",
      "69/69 [==============================] - 60s 872ms/step - loss: 0.0230 - accuracy: 0.6655 - val_loss: 0.1822 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "69/69 [==============================] - 48s 698ms/step - loss: 0.0212 - accuracy: 0.6782 - val_loss: 0.2858 - val_accuracy: 0.8548\n",
      "Epoch 132/500\n",
      "69/69 [==============================] - 48s 691ms/step - loss: 0.0174 - accuracy: 0.6618 - val_loss: 0.2811 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "69/69 [==============================] - 52s 747ms/step - loss: 0.0274 - accuracy: 0.6836 - val_loss: 0.3012 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "69/69 [==============================] - 68s 984ms/step - loss: 0.0187 - accuracy: 0.6709 - val_loss: 0.2937 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0169 - accuracy: 0.6745 - val_loss: 0.3050 - val_accuracy: 0.8387\n",
      "Epoch 136/500\n",
      "69/69 [==============================] - 49s 712ms/step - loss: 0.0161 - accuracy: 0.6291 - val_loss: 0.2511 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "69/69 [==============================] - 46s 672ms/step - loss: 0.0151 - accuracy: 0.6964 - val_loss: 0.2912 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "69/69 [==============================] - 46s 673ms/step - loss: 0.0161 - accuracy: 0.6745 - val_loss: 0.3479 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0118 - accuracy: 0.7055 - val_loss: 0.2411 - val_accuracy: 0.9839\n",
      "Epoch 140/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0126 - accuracy: 0.6909 - val_loss: 0.2612 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "69/69 [==============================] - 58s 845ms/step - loss: 0.0120 - accuracy: 0.6636 - val_loss: 0.2567 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "69/69 [==============================] - 55s 801ms/step - loss: 0.0126 - accuracy: 0.6909 - val_loss: 0.2437 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "69/69 [==============================] - 54s 789ms/step - loss: 0.0107 - accuracy: 0.6855 - val_loss: 0.2307 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "69/69 [==============================] - 56s 812ms/step - loss: 0.0094 - accuracy: 0.6836 - val_loss: 0.2668 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "69/69 [==============================] - 68s 980ms/step - loss: 0.0117 - accuracy: 0.6782 - val_loss: 0.3057 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "69/69 [==============================] - 67s 976ms/step - loss: 0.0100 - accuracy: 0.6982 - val_loss: 0.2230 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "69/69 [==============================] - 66s 955ms/step - loss: 0.0106 - accuracy: 0.6509 - val_loss: 0.3489 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "69/69 [==============================] - 48s 699ms/step - loss: 0.0086 - accuracy: 0.7073 - val_loss: 0.2491 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "69/69 [==============================] - 48s 695ms/step - loss: 0.0077 - accuracy: 0.6636 - val_loss: 0.2577 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "69/69 [==============================] - 48s 703ms/step - loss: 0.0084 - accuracy: 0.7073 - val_loss: 0.3090 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "69/69 [==============================] - 49s 707ms/step - loss: 0.0086 - accuracy: 0.6455 - val_loss: 0.3122 - val_accuracy: 0.3387\n",
      "Epoch 152/500\n",
      "69/69 [==============================] - 89s 1s/step - loss: 0.0093 - accuracy: 0.6782 - val_loss: 0.3343 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "69/69 [==============================] - 73s 1s/step - loss: 0.0095 - accuracy: 0.7109 - val_loss: 0.2736 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "69/69 [==============================] - 49s 717ms/step - loss: 0.0090 - accuracy: 0.6800 - val_loss: 0.2440 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "69/69 [==============================] - 48s 699ms/step - loss: 0.0098 - accuracy: 0.6745 - val_loss: 0.3705 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "69/69 [==============================] - 48s 702ms/step - loss: 0.0114 - accuracy: 0.6709 - val_loss: 0.3163 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "69/69 [==============================] - 50s 725ms/step - loss: 0.0102 - accuracy: 0.6764 - val_loss: 0.2072 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "69/69 [==============================] - 92s 1s/step - loss: 0.0104 - accuracy: 0.7127 - val_loss: 0.2721 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0126 - accuracy: 0.6727 - val_loss: 0.2756 - val_accuracy: 0.9839\n",
      "Epoch 160/500\n",
      "69/69 [==============================] - 56s 817ms/step - loss: 0.0119 - accuracy: 0.6691 - val_loss: 0.2295 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "69/69 [==============================] - 58s 841ms/step - loss: 0.0105 - accuracy: 0.6836 - val_loss: 0.3042 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "69/69 [==============================] - 55s 790ms/step - loss: 0.0075 - accuracy: 0.6964 - val_loss: 0.2988 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "69/69 [==============================] - 58s 834ms/step - loss: 0.0072 - accuracy: 0.6727 - val_loss: 0.3230 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "69/69 [==============================] - 56s 818ms/step - loss: 0.0074 - accuracy: 0.6764 - val_loss: 0.2131 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "69/69 [==============================] - 93s 1s/step - loss: 0.0069 - accuracy: 0.6818 - val_loss: 0.2665 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 64s 926ms/step - loss: 0.0060 - accuracy: 0.6891 - val_loss: 0.2518 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "69/69 [==============================] - 46s 663ms/step - loss: 0.0074 - accuracy: 0.6818 - val_loss: 0.3487 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "69/69 [==============================] - 46s 663ms/step - loss: 0.0146 - accuracy: 0.6909 - val_loss: 0.2498 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "69/69 [==============================] - 49s 705ms/step - loss: 0.0126 - accuracy: 0.6727 - val_loss: 0.3935 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "69/69 [==============================] - 51s 744ms/step - loss: 0.0092 - accuracy: 0.6709 - val_loss: 0.2469 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "69/69 [==============================] - 71s 1s/step - loss: 0.0088 - accuracy: 0.6691 - val_loss: 0.2457 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "69/69 [==============================] - 68s 983ms/step - loss: 0.0075 - accuracy: 0.7018 - val_loss: 0.2449 - val_accuracy: 0.9839\n",
      "Epoch 173/500\n",
      "69/69 [==============================] - 64s 925ms/step - loss: 0.0074 - accuracy: 0.6818 - val_loss: 0.3223 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "69/69 [==============================] - 44s 631ms/step - loss: 0.0087 - accuracy: 0.7036 - val_loss: 0.2505 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "69/69 [==============================] - 43s 621ms/step - loss: 0.0095 - accuracy: 0.6818 - val_loss: 0.3062 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "69/69 [==============================] - 44s 637ms/step - loss: 0.0092 - accuracy: 0.7127 - val_loss: 0.2276 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "69/69 [==============================] - 44s 638ms/step - loss: 0.0082 - accuracy: 0.6982 - val_loss: 0.2686 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "69/69 [==============================] - 67s 972ms/step - loss: 0.0105 - accuracy: 0.6873 - val_loss: 0.3024 - val_accuracy: 0.9839\n",
      "Epoch 179/500\n",
      "69/69 [==============================] - 92s 1s/step - loss: 0.0110 - accuracy: 0.6782 - val_loss: 0.3526 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "69/69 [==============================] - 53s 762ms/step - loss: 0.0102 - accuracy: 0.6618 - val_loss: 0.2974 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "69/69 [==============================] - 46s 670ms/step - loss: 0.0118 - accuracy: 0.6764 - val_loss: 0.2621 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "69/69 [==============================] - 47s 675ms/step - loss: 0.0191 - accuracy: 0.6709 - val_loss: 0.2410 - val_accuracy: 0.4032\n",
      "Epoch 183/500\n",
      "69/69 [==============================] - 46s 670ms/step - loss: 0.0077 - accuracy: 0.6745 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "69/69 [==============================] - 65s 946ms/step - loss: 0.0068 - accuracy: 0.6873 - val_loss: 0.2366 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "69/69 [==============================] - 68s 986ms/step - loss: 0.0083 - accuracy: 0.6891 - val_loss: 0.2695 - val_accuracy: 0.9516\n",
      "Epoch 186/500\n",
      "69/69 [==============================] - 66s 950ms/step - loss: 0.0076 - accuracy: 0.6582 - val_loss: 0.2975 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "69/69 [==============================] - 42s 609ms/step - loss: 0.0064 - accuracy: 0.6982 - val_loss: 0.2312 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "69/69 [==============================] - 43s 621ms/step - loss: 0.0079 - accuracy: 0.6800 - val_loss: 0.2657 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "69/69 [==============================] - 46s 662ms/step - loss: 0.0159 - accuracy: 0.6582 - val_loss: 0.1985 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "69/69 [==============================] - 43s 622ms/step - loss: 0.0080 - accuracy: 0.6655 - val_loss: 0.3255 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "69/69 [==============================] - 68s 984ms/step - loss: 0.0064 - accuracy: 0.7073 - val_loss: 0.2738 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "69/69 [==============================] - 95s 1s/step - loss: 0.0060 - accuracy: 0.7091 - val_loss: 0.2507 - val_accuracy: 0.9677\n",
      "Epoch 193/500\n",
      "69/69 [==============================] - 63s 910ms/step - loss: 0.0060 - accuracy: 0.7236 - val_loss: 0.2616 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "69/69 [==============================] - 42s 611ms/step - loss: 0.0061 - accuracy: 0.7073 - val_loss: 0.2396 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "69/69 [==============================] - 46s 664ms/step - loss: 0.0060 - accuracy: 0.7000 - val_loss: 0.2848 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "69/69 [==============================] - 44s 636ms/step - loss: 0.0107 - accuracy: 0.6782 - val_loss: 0.2273 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "69/69 [==============================] - 43s 619ms/step - loss: 0.0055 - accuracy: 0.7091 - val_loss: 0.2903 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "69/69 [==============================] - 47s 677ms/step - loss: 0.0064 - accuracy: 0.7000 - val_loss: 0.2019 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "69/69 [==============================] - 56s 806ms/step - loss: 0.0073 - accuracy: 0.7091 - val_loss: 0.2135 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "69/69 [==============================] - 90s 1s/step - loss: 0.0059 - accuracy: 0.7145 - val_loss: 0.2062 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "69/69 [==============================] - 74s 1s/step - loss: 0.0207 - accuracy: 0.6873 - val_loss: 0.2428 - val_accuracy: 0.9677\n",
      "Epoch 202/500\n",
      "69/69 [==============================] - 45s 651ms/step - loss: 0.0469 - accuracy: 0.5564 - val_loss: 0.9335 - val_accuracy: 0.1613\n",
      "Epoch 203/500\n",
      "69/69 [==============================] - 47s 678ms/step - loss: 0.2549 - accuracy: 0.5218 - val_loss: 0.3190 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "69/69 [==============================] - 46s 666ms/step - loss: 0.1754 - accuracy: 0.4945 - val_loss: 0.6982 - val_accuracy: 0.7581\n",
      "Epoch 205/500\n",
      "69/69 [==============================] - 46s 669ms/step - loss: 0.0564 - accuracy: 0.5873 - val_loss: 0.1536 - val_accuracy: 0.9677\n",
      "Epoch 206/500\n",
      "69/69 [==============================] - 64s 921ms/step - loss: 0.0350 - accuracy: 0.6145 - val_loss: 0.3158 - val_accuracy: 0.9839\n",
      "Epoch 207/500\n",
      "69/69 [==============================] - 70s 1s/step - loss: 0.0279 - accuracy: 0.6545 - val_loss: 0.2504 - val_accuracy: 0.9516\n"
     ]
    }
   ],
   "source": [
    "# Model checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('efficientnet_v1.h5', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=200, monitor='val_loss'), tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "\n",
    "results = model.fit(x_training, y_training, validation_split=0.10, batch_size=8, epochs=500, callbacks=callbacks)\n",
    "model.save(\"efficientnet_v1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable import from different directory\n",
    "import sys\n",
    "sys.path.insert(0, 'D:/comma2k19_dataset/notebooks/lib/')\n",
    "from common.transformations.camera import transform_img, eon_intrinsics\n",
    "from common.transformations.model import medmodel_intrinsics\n",
    "\n",
    "\n",
    "VIDEO_PATH = 'D:/comma2k19_dataset/10/video.hevc'\n",
    "\n",
    "TOTAL_FRAMES = 1200\n",
    "bgr_imgs = []\n",
    "yuv_imgs = []\n",
    "\n",
    "\n",
    "vid = cv2.VideoCapture(VIDEO_PATH)\n",
    "for frame_number in tqdm(range(TOTAL_FRAMES)):\n",
    "    ret, frame = vid.read()\n",
    "    if (frame_number % 5 == 0):\n",
    "        bgr_imgs.append(frame)\n",
    "        frame = cv2.resize(frame,(1164,874))\n",
    "        img_yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)\n",
    "        yuv_imgs.append(img_yuv)\n",
    "\n",
    "\n",
    "\n",
    "def frames_to_tensor(frames):                                                                                               \n",
    "    H = (frames.shape[1]*2)//3                                                                                                \n",
    "    W = frames.shape[2]                                                                                                       \n",
    "    in_img1 = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.uint8)                                                      \n",
    "                                                                                                                            \n",
    "    in_img1[:, 0] = frames[:, 0:H:2, 0::2]                                                                                    \n",
    "    in_img1[:, 1] = frames[:, 1:H:2, 0::2]                                                                                    \n",
    "    in_img1[:, 2] = frames[:, 0:H:2, 1::2]                                                                                    \n",
    "    in_img1[:, 3] = frames[:, 1:H:2, 1::2]                                                                                    \n",
    "    in_img1[:, 4] = frames[:, H:H+H//4].reshape((-1, H//2,W//2))                                                              \n",
    "    in_img1[:, 5] = frames[:, H+H//4:H+H//2].reshape((-1, H//2,W//2))\n",
    "    return in_img1\n",
    "\n",
    "imgs_med_model = np.zeros((len(yuv_imgs), 384, 512), dtype=np.uint8)\n",
    "for i, img in tqdm(enumerate(yuv_imgs)):\n",
    "    imgs_med_model[i] = transform_img(img, from_intr=eon_intrinsics, to_intr=medmodel_intrinsics, yuv=True,\n",
    "                                    output_size=(512,256))\n",
    "frame_tensors = frames_to_tensor(np.array(imgs_med_model)).astype(np.float32)/128.0 - 1.0\n",
    "\n",
    "figsize(12,12);\n",
    "imshow(bgr_imgs[0]);\n",
    "title('First Image', fontsize=25);\n",
    "\n",
    "outs = model.predict(frame_tensors, verbose=1)\n",
    "data_length = len(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verification_folder = \"validation\"\n",
    "# Get the length of the data\n",
    "\n",
    "for i in tqdm(range(data_length)):\n",
    "    verification_img = bgr_imgs[i]\n",
    "    forward_data = np.linspace(0,99,100)\n",
    "    down_data = np.zeros(100)\n",
    "    draw_path(np.transpose([forward_data,outs[i],down_data]), img=verification_img, isTest = True)\n",
    "        \n",
    "    cv2.imwrite(os.path.join(verification_folder , str(i) + '.jpg'), verification_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
